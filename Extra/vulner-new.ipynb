{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9331031,"sourceType":"datasetVersion","datasetId":5653652}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"What is Vulngpt ?\n-This is ","metadata":{}},{"cell_type":"markdown","source":"**Import the Necessary libraries **","metadata":{}},{"cell_type":"code","source":"!pip install transformers pandas torch flask beautifulsoup4 requests\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:31:58.195306Z","iopub.execute_input":"2024-09-06T06:31:58.195649Z","iopub.status.idle":"2024-09-06T06:32:10.449061Z","shell.execute_reply.started":"2024-09-06T06:31:58.195616Z","shell.execute_reply":"2024-09-06T06:32:10.447794Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: flask in /opt/conda/lib/python3.10/site-packages (3.0.3)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.5.0)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from flask) (3.0.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from flask) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from flask) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from flask) (1.8.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport re\n\ndef scrape_website(url):\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n    }\n    try:\n        response = requests.get(url, headers=headers, timeout=30)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        return soup.prettify()\n    except requests.exceptions.RequestException as e:\n        print(f\"Error while fetching the URL: {e}\")\n        return None\n\ndef extract_sql_queries(code):\n    # Regex to find SQL queries (basic example)\n    sql_pattern = re.compile(r\"(SELECT|INSERT|UPDATE|DELETE)\\s.*\\s(FROM|INTO|SET)\\s.*\", re.IGNORECASE)\n    queries = sql_pattern.findall(code)\n    return [' '.join(query) for query in queries]\n\ndef detect_sqli(query):\n    # Simple rule-based detection (for illustration purposes)\n    sqli_patterns = [\n        r\"'.*'\",               # Unescaped single quotes\n        r\"\\\".*\\\"\",             # Unescaped double quotes\n        r\"OR\\s1=1\",            # Typical SQLi payload\n        r\"--\",                 # Comment injection\n        r\";\\sDROP\\sTABLE\",     # Dangerous SQL keywords\n        \n    ]\n\n    for pattern in sqli_patterns:\n        if re.search(pattern, query, re.IGNORECASE):\n            return True\n    return False\n\n\nurl = 'https://www.facebook.com/'  # Replace with the URL you want to test\nwebsite_code = scrape_website(url)\n\nif website_code:\n    # Extract SQL queries from the website code\n    sql_queries = extract_sql_queries(website_code)\n    print(f\"SQL Queries Found: {sql_queries}\")  # Debugging line to check the content\n\n    if sql_queries:\n        # Detect SQLi in each SQL query\n        for query in sql_queries:\n            if detect_sqli(query):\n                print(f\"Possible SQL Injection vulnerability detected in query: {query}\")\n            else:\n                print(f\"Safe SQL query: {query}\")\n    else:\n        print(\"No SQL queries found.\")\nelse:\n    print(\"Failed to retrieve website code.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:27:49.052550Z","iopub.execute_input":"2024-09-11T05:27:49.052974Z","iopub.status.idle":"2024-09-11T05:27:49.644298Z","shell.execute_reply.started":"2024-09-11T05:27:49.052922Z","shell.execute_reply":"2024-09-11T05:27:49.643320Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"SQL Queries Found: ['Delete from']\nSafe SQL query: Delete from\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaForSequenceClassification\nimport torch\n\n# Load pre-trained RoBERTa tokenizer and model\nroberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nroberta_model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=5)  \n\n# Define vulnerability types that RoBERTa can detect\nvulnerability_types = {\n    0: 'Safe',\n    1: 'Cross-Site Scripting (XSS)',\n    2: 'Cross-Site Request Forgery (CSRF)',\n    3: 'Remote Code Execution (RCE)',\n}\n# Detect vulnerabilities using RoBERTa\ndef detect_vulnerabilities(code):\n    inputs = roberta_tokenizer(code, return_tensors='pt', max_length=512, truncation=True)\n    outputs = roberta_model(**inputs)\n    prediction = torch.argmax(outputs.logits, dim=1).item()\n    return vulnerability_types[prediction]\n# Example usage with website code\nvulnerability_status = detect_vulnerabilities(website_code)\nprint(f\"Vulnerability Detected: {vulnerability_status}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\n\n# Load GPT-2 tokenizer and model\ngpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ngpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n\n# Generate remediation suggestions\ndef generate_remediation_suggestion(vulnerability_type):\n    input_text = f\"The following vulnerability was detected: {vulnerability_type}. Suggested remediation: \"\n    input_ids = gpt2_tokenizer.encode(input_text, return_tensors='pt')\n    output = gpt2_model.generate(input_ids, max_length=100, num_return_sequences=1)\n    suggestion = gpt2_tokenizer.decode(output[0], skip_special_tokens=True)\n    return suggestion\n\n# Example usage if the website is vulnerable\nif vulnerability_status != 'Safe':\n    remediation_suggestion = generate_remediation_suggestion(vulnerability_status)\n    print(f\"Remediation Suggestion: {remediation_suggestion}\")\nelse:\n    print(\"No vulnerabilities detected.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T08:32:59.488889Z","iopub.execute_input":"2024-09-11T08:32:59.489701Z","iopub.status.idle":"2024-09-11T08:33:04.594502Z","shell.execute_reply.started":"2024-09-11T08:32:59.489668Z","shell.execute_reply":"2024-09-11T08:33:04.593172Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1c95409fee048a28d7563334095e170"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f344af497943465aad274e34b4185ada"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce9fa9508e044968ac3adb507a908a88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3180c045dd8d4a26b52cc137a580840f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a09630011cd4231ab989c06c88034cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6725d481d3d94cf0bab310b655780c5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9732a2001554c7e8f73ec19cf2ab9f7"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m suggestion\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Example usage if the website is vulnerable\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvulnerability_status\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSafe\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     17\u001b[0m     remediation_suggestion \u001b[38;5;241m=\u001b[39m generate_remediation_suggestion(vulnerability_status)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemediation Suggestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremediation_suggestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'vulnerability_status' is not defined"],"ename":"NameError","evalue":"name 'vulnerability_status' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Dataset Preparing :**","metadata":{}},{"cell_type":"code","source":"!pip install pandas\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:00:31.850098Z","iopub.execute_input":"2024-09-06T07:00:31.850466Z","iopub.status.idle":"2024-09-06T07:00:43.991450Z","shell.execute_reply.started":"2024-09-06T07:00:31.850437Z","shell.execute_reply":"2024-09-06T07:00:43.990417Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Load dataset\ndataset_path = '/kaggle/input/vulnerbility/vulnerability_dataset.csv'  # Path to your dataset\ndata = pd.read_csv(dataset_path)\n\n# Preview the dataset\nprint(data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:01:43.125749Z","iopub.execute_input":"2024-09-06T07:01:43.126593Z","iopub.status.idle":"2024-09-06T07:01:43.551395Z","shell.execute_reply.started":"2024-09-06T07:01:43.126548Z","shell.execute_reply":"2024-09-06T07:01:43.550504Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"                                     code          label\n0          <script>alert('XSS');</script>            XSS\n1      SELECT * FROM users WHERE id = $id  SQL Injection\n2   <form action='/submit' method='POST'>           CSRF\n3                  <h1>Hello, World!</h1>           Safe\n4  <img src='invalid' onerror='alert(1)'>            XSS\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import RobertaTokenizer\nfrom sklearn.model_selection import train_test_split\n\n# Load the tokenizer\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n# Tokenize the dataset\ndef tokenize_function(example):\n    return tokenizer(example['code'], padding=\"max_length\", truncation=True, max_length=512)\n\n# Split data into train and test sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(data['code'], data['label'], test_size=0.2)\n\n# Tokenize the training and test data\ntrain_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\ntest_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=512)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:02:07.068847Z","iopub.execute_input":"2024-09-06T07:02:07.069442Z","iopub.status.idle":"2024-09-06T07:02:12.235921Z","shell.execute_reply.started":"2024-09-06T07:02:07.069412Z","shell.execute_reply":"2024-09-06T07:02:12.235161Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa297ddbb4394b3a8c854a7aab95f12d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a08408e31e674621a714fc98a51e7d69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ab23f874be6468bbaa3913e548c1bea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a9ae971d8044f84be368954b9d53136"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e9381e7f0424666ae73a4bec7c2ac41"}},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Convert string labels into integers\nlabel_encoder = LabelEncoder()\ntrain_labels = label_encoder.fit_transform(train_labels)\ntest_labels = label_encoder.transform(test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:02:48.365082Z","iopub.execute_input":"2024-09-06T07:02:48.366559Z","iopub.status.idle":"2024-09-06T07:02:48.374062Z","shell.execute_reply.started":"2024-09-06T07:02:48.366520Z","shell.execute_reply":"2024-09-06T07:02:48.373328Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass VulnerabilityDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create PyTorch dataset objects\ntrain_dataset = VulnerabilityDataset(train_encodings, train_labels)\ntest_dataset = VulnerabilityDataset(test_encodings, test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:02:54.769383Z","iopub.execute_input":"2024-09-06T07:02:54.770162Z","iopub.status.idle":"2024-09-06T07:02:54.776614Z","shell.execute_reply.started":"2024-09-06T07:02:54.770133Z","shell.execute_reply":"2024-09-06T07:02:54.775752Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments\n\n# Load pre-trained RoBERTa model with classification head\nmodel = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(label_encoder.classes_))\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    num_train_epochs=3,              # number of training epochs\n    per_device_train_batch_size=8,   # batch size for training\n    per_device_eval_batch_size=8,    # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n    evaluation_strategy=\"steps\"\n)\n\n# Create Trainer instance\ntrainer = Trainer(\n    model=model,                         # the model to be trained\n    args=training_args,                  # training arguments\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=test_dataset            # evaluation dataset\n)\n\n# Fine-tune the model\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:02:58.140155Z","iopub.execute_input":"2024-09-06T07:02:58.140485Z","iopub.status.idle":"2024-09-06T07:11:05.978787Z","shell.execute_reply.started":"2024-09-06T07:02:58.140461Z","shell.execute_reply":"2024-09-06T07:11:05.977972Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2024-09-06 07:03:00.498190: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-06 07:03:00.498331: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-06 07:03:00.619390: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fad6652bf2a74c70974030cb7e24f394"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.9 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240906_071026-e4weo51f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface/runs/e4weo51f' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface' target=\"_blank\">https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface/runs/e4weo51f' target=\"_blank\">https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface/runs/e4weo51f</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [222/222 00:22, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.359900</td>\n      <td>2.353521</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.316200</td>\n      <td>2.318360</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.281800</td>\n      <td>2.251393</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.167500</td>\n      <td>2.088924</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.879700</td>\n      <td>1.262213</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.120500</td>\n      <td>0.882433</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.910600</td>\n      <td>0.670563</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.788800</td>\n      <td>0.541834</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.526500</td>\n      <td>0.481046</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.341500</td>\n      <td>0.423522</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.489800</td>\n      <td>0.389650</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.293400</td>\n      <td>0.382742</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.368600</td>\n      <td>0.357517</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.432300</td>\n      <td>0.324538</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.589000</td>\n      <td>0.301198</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.378100</td>\n      <td>0.278455</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.324900</td>\n      <td>0.246891</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.234000</td>\n      <td>0.209663</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.222100</td>\n      <td>0.178116</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.214100</td>\n      <td>0.177746</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.196500</td>\n      <td>0.153864</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.161900</td>\n      <td>0.159207</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=222, training_loss=0.8383341494712744, metrics={'train_runtime': 471.0578, 'train_samples_per_second': 3.732, 'train_steps_per_second': 0.471, 'total_flos': 29814885095688.0, 'train_loss': 0.8383341494712744, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Load the fine-tuned model and tokenizer\nmodel = RobertaForSequenceClassification.from_pretrained('./fine_tuned_roberta')\ntokenizer = RobertaTokenizer.from_pretrained('./fine_tuned_roberta')\n\n# Detect vulnerabilities in the website code\ndef detect_vulnerability_with_fine_tuned_model(code):\n    inputs = tokenizer(code, return_tensors='pt', truncation=True, padding=True, max_length=512)\n    outputs = model(**inputs)\n    prediction = torch.argmax(outputs.logits, dim=1).item()\n    return label_encoder.inverse_transform([prediction])[0]\n\n\nvulnerability_type = detect_vulnerability_with_fine_tuned_model(website_code)\nprint(f\"Detected vulnerability: {vulnerability_type}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T03:29:12.689289Z","iopub.execute_input":"2024-09-11T03:29:12.689924Z","iopub.status.idle":"2024-09-11T03:29:13.818974Z","shell.execute_reply.started":"2024-09-11T03:29:12.689893Z","shell.execute_reply":"2024-09-11T03:29:13.817474Z"},"trusted":true},"execution_count":39,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './fine_tuned_roberta'.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the fine-tuned model and tokenizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRobertaForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./fine_tuned_roberta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m RobertaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./fine_tuned_roberta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Detect vulnerabilities in the website code\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3128\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   3127\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 3128\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3141\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3142\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3143\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:466\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n","\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: './fine_tuned_roberta'. Please provide either the path to a local folder or the repo_id of a model on the Hub."],"ename":"OSError","evalue":"Incorrect path_or_model_id: './fine_tuned_roberta'. Please provide either the path to a local folder or the repo_id of a model on the Hub.","output_type":"error"}]}]}