{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9331031,"sourceType":"datasetVersion","datasetId":5653652}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"What is Vulngpt ?\n-This is ","metadata":{}},{"cell_type":"markdown","source":"**Import the Necessary libraries **","metadata":{}},{"cell_type":"code","source":"!pip install transformers pandas torch flask beautifulsoup4 requests\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:31:58.195306Z","iopub.execute_input":"2024-09-06T06:31:58.195649Z","iopub.status.idle":"2024-09-06T06:32:10.449061Z","shell.execute_reply.started":"2024-09-06T06:31:58.195616Z","shell.execute_reply":"2024-09-06T06:32:10.447794Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: flask in /opt/conda/lib/python3.10/site-packages (3.0.3)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.5.0)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from flask) (3.0.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from flask) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from flask) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from flask) (1.8.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport re\n\ndef scrape_website(url):\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n    }\n    try:\n        response = requests.get(url, headers=headers, timeout=30)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        return soup.prettify()\n    except requests.exceptions.RequestException as e:\n        print(f\"Error while fetching the URL: {e}\")\n        return None\n\ndef extract_sql_queries(code):\n    # Regex to find SQL queries (basic example)\n    sql_pattern = re.compile(r\"(SELECT|INSERT|UPDATE|DELETE)\\s.*\\s(FROM|INTO|SET)\\s.*\", re.IGNORECASE)\n    queries = sql_pattern.findall(code)\n    return [' '.join(query) for query in queries]\n\ndef detect_sqli(query):\n    # Simple rule-based detection (for illustration purposes)\n    sqli_patterns = [\n        r\"'.*'\",               # Unescaped single quotes\n        r\"\\\".*\\\"\",             # Unescaped double quotes\n        r\"OR\\s1=1\",            # Typical SQLi payload\n        r\"--\",                 # Comment injection\n        r\";\\sDROP\\sTABLE\",     # Dangerous SQL keywords\n        \n    ]\n\n    for pattern in sqli_patterns:\n        if re.search(pattern, query, re.IGNORECASE):\n            return True\n    return False\n\n\nurl = 'https://www.facebook.com/'  # Replace with the URL you want to test\nwebsite_code = scrape_website(url)\n\nif website_code:\n    # Extract SQL queries from the website code\n    sql_queries = extract_sql_queries(website_code)\n    print(f\"SQL Queries Found: {sql_queries}\")  # Debugging line to check the content\n\n    if sql_queries:\n        # Detect SQLi in each SQL query\n        for query in sql_queries:\n            if detect_sqli(query):\n                print(f\"Possible SQL Injection vulnerability detected in query: {query}\")\n            else:\n                print(f\"Safe SQL query: {query}\")\n    else:\n        print(\"No SQL queries found.\")\nelse:\n    print(\"Failed to retrieve website code.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T05:27:49.052550Z","iopub.execute_input":"2024-09-11T05:27:49.052974Z","iopub.status.idle":"2024-09-11T05:27:49.644298Z","shell.execute_reply.started":"2024-09-11T05:27:49.052922Z","shell.execute_reply":"2024-09-11T05:27:49.643320Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"SQL Queries Found: ['Delete from']\nSafe SQL query: Delete from\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaForSequenceClassification\nimport torch\n\n# Load pre-trained RoBERTa tokenizer and model\nroberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nroberta_model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=5)  \n\n# Define vulnerability types that RoBERTa can detect\nvulnerability_types = {\n    0: 'Safe',\n    1: 'Cross-Site Scripting (XSS)',\n    2: 'Cross-Site Request Forgery (CSRF)',\n    3: 'Remote Code Execution (RCE)',\n}\n# Detect vulnerabilities using RoBERTa\ndef detect_vulnerabilities(code):\n    inputs = roberta_tokenizer(code, return_tensors='pt', max_length=512, truncation=True)\n    outputs = roberta_model(**inputs)\n    prediction = torch.argmax(outputs.logits, dim=1).item()\n    return vulnerability_types[prediction]\n# Example usage with website code\nvulnerability_status = detect_vulnerabilities(website_code)\nprint(f\"Vulnerability Detected: {vulnerability_status}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\n\n# Load GPT-2 tokenizer and model\ngpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ngpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n\n# Generate remediation suggestions\ndef generate_remediation_suggestion(vulnerability_type):\n    input_text = f\"The following vulnerability was detected: {vulnerability_type}. Suggested remediation: \"\n    input_ids = gpt2_tokenizer.encode(input_text, return_tensors='pt')\n    output = gpt2_model.generate(input_ids, max_length=100, num_return_sequences=1)\n    suggestion = gpt2_tokenizer.decode(output[0], skip_special_tokens=True)\n    return suggestion\n\n# Example usage if the website is vulnerable\nif vulnerability_status != 'Safe':\n    remediation_suggestion = generate_remediation_suggestion(vulnerability_status)\n    print(f\"Remediation Suggestion: {remediation_suggestion}\")\nelse:\n    print(\"No vulnerabilities detected.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T08:32:59.488889Z","iopub.execute_input":"2024-09-11T08:32:59.489701Z","iopub.status.idle":"2024-09-11T08:33:04.594502Z","shell.execute_reply.started":"2024-09-11T08:32:59.489668Z","shell.execute_reply":"2024-09-11T08:33:04.593172Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1c95409fee048a28d7563334095e170"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f344af497943465aad274e34b4185ada"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce9fa9508e044968ac3adb507a908a88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3180c045dd8d4a26b52cc137a580840f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a09630011cd4231ab989c06c88034cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6725d481d3d94cf0bab310b655780c5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9732a2001554c7e8f73ec19cf2ab9f7"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m suggestion\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Example usage if the website is vulnerable\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvulnerability_status\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSafe\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     17\u001b[0m     remediation_suggestion \u001b[38;5;241m=\u001b[39m generate_remediation_suggestion(vulnerability_status)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemediation Suggestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremediation_suggestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'vulnerability_status' is not defined"],"ename":"NameError","evalue":"name 'vulnerability_status' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Dataset Preparing :**","metadata":{}},{"cell_type":"code","source":"!pip install pandas\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:00:31.850098Z","iopub.execute_input":"2024-09-06T07:00:31.850466Z","iopub.status.idle":"2024-09-06T07:00:43.991450Z","shell.execute_reply.started":"2024-09-06T07:00:31.850437Z","shell.execute_reply":"2024-09-06T07:00:43.990417Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Load dataset\ndataset_path = '/kaggle/input/vulnerbility/vulnerability_dataset.csv'  # Path to your dataset\ndata = pd.read_csv(dataset_path)\n\n# Preview the dataset\nprint(data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:01:43.125749Z","iopub.execute_input":"2024-09-06T07:01:43.126593Z","iopub.status.idle":"2024-09-06T07:01:43.551395Z","shell.execute_reply.started":"2024-09-06T07:01:43.126548Z","shell.execute_reply":"2024-09-06T07:01:43.550504Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"                                     code          label\n0          <script>alert('XSS');</script>            XSS\n1      SELECT * FROM users WHERE id = $id  SQL Injection\n2   <form action='/submit' method='POST'>           CSRF\n3                  <h1>Hello, World!</h1>           Safe\n4  <img src='invalid' onerror='alert(1)'>            XSS\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import RobertaTokenizer\nfrom sklearn.model_selection import train_test_split\n\n# Load the tokenizer\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n# Tokenize the dataset\ndef tokenize_function(example):\n    return tokenizer(example['code'], padding=\"max_length\", truncation=True, max_length=512)\n\n# Split data into train and test sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(data['code'], data['label'], test_size=0.2)\n\n# Tokenize the training and test data\ntrain_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\ntest_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=512)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:02:07.068847Z","iopub.execute_input":"2024-09-06T07:02:07.069442Z","iopub.status.idle":"2024-09-06T07:02:12.235921Z","shell.execute_reply.started":"2024-09-06T07:02:07.069412Z","shell.execute_reply":"2024-09-06T07:02:12.235161Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa297ddbb4394b3a8c854a7aab95f12d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a08408e31e674621a714fc98a51e7d69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ab23f874be6468bbaa3913e548c1bea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a9ae971d8044f84be368954b9d53136"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e9381e7f0424666ae73a4bec7c2ac41"}},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Convert string labels into integers\nlabel_encoder = LabelEncoder()\ntrain_labels = label_encoder.fit_transform(train_labels)\ntest_labels = label_encoder.transform(test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:02:48.365082Z","iopub.execute_input":"2024-09-06T07:02:48.366559Z","iopub.status.idle":"2024-09-06T07:02:48.374062Z","shell.execute_reply.started":"2024-09-06T07:02:48.366520Z","shell.execute_reply":"2024-09-06T07:02:48.373328Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass VulnerabilityDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create PyTorch dataset objects\ntrain_dataset = VulnerabilityDataset(train_encodings, train_labels)\ntest_dataset = VulnerabilityDataset(test_encodings, test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:02:54.769383Z","iopub.execute_input":"2024-09-06T07:02:54.770162Z","iopub.status.idle":"2024-09-06T07:02:54.776614Z","shell.execute_reply.started":"2024-09-06T07:02:54.770133Z","shell.execute_reply":"2024-09-06T07:02:54.775752Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments\n\n# Load pre-trained RoBERTa model with classification head\nmodel = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(label_encoder.classes_))\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    num_train_epochs=3,              # number of training epochs\n    per_device_train_batch_size=8,   # batch size for training\n    per_device_eval_batch_size=8,    # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n    evaluation_strategy=\"steps\"\n)\n\n# Create Trainer instance\ntrainer = Trainer(\n    model=model,                         # the model to be trained\n    args=training_args,                  # training arguments\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=test_dataset            # evaluation dataset\n)\n\n# Fine-tune the model\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:02:58.140155Z","iopub.execute_input":"2024-09-06T07:02:58.140485Z","iopub.status.idle":"2024-09-06T07:11:05.978787Z","shell.execute_reply.started":"2024-09-06T07:02:58.140461Z","shell.execute_reply":"2024-09-06T07:11:05.977972Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2024-09-06 07:03:00.498190: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-06 07:03:00.498331: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-06 07:03:00.619390: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fad6652bf2a74c70974030cb7e24f394"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.9 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240906_071026-e4weo51f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface/runs/e4weo51f' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface' target=\"_blank\">https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface/runs/e4weo51f' target=\"_blank\">https://wandb.ai/rezaurrahmanratul-United%20International%20University/huggingface/runs/e4weo51f</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [222/222 00:22, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.359900</td>\n      <td>2.353521</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.316200</td>\n      <td>2.318360</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.281800</td>\n      <td>2.251393</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.167500</td>\n      <td>2.088924</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.879700</td>\n      <td>1.262213</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.120500</td>\n      <td>0.882433</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.910600</td>\n      <td>0.670563</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.788800</td>\n      <td>0.541834</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.526500</td>\n      <td>0.481046</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.341500</td>\n      <td>0.423522</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.489800</td>\n      <td>0.389650</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.293400</td>\n      <td>0.382742</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.368600</td>\n      <td>0.357517</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.432300</td>\n      <td>0.324538</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.589000</td>\n      <td>0.301198</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.378100</td>\n      <td>0.278455</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.324900</td>\n      <td>0.246891</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.234000</td>\n      <td>0.209663</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.222100</td>\n      <td>0.178116</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.214100</td>\n      <td>0.177746</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.196500</td>\n      <td>0.153864</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.161900</td>\n      <td>0.159207</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=222, training_loss=0.8383341494712744, metrics={'train_runtime': 471.0578, 'train_samples_per_second': 3.732, 'train_steps_per_second': 0.471, 'total_flos': 29814885095688.0, 'train_loss': 0.8383341494712744, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Load the fine-tuned model and tokenizer\nmodel = RobertaForSequenceClassification.from_pretrained('./fine_tuned_roberta')\ntokenizer = RobertaTokenizer.from_pretrained('./fine_tuned_roberta')\n\n# Detect vulnerabilities in the website code\ndef detect_vulnerability_with_fine_tuned_model(code):\n    inputs = tokenizer(code, return_tensors='pt', truncation=True, padding=True, max_length=512)\n    outputs = model(**inputs)\n    prediction = torch.argmax(outputs.logits, dim=1).item()\n    return label_encoder.inverse_transform([prediction])[0]\n\n\nvulnerability_type = detect_vulnerability_with_fine_tuned_model(website_code)\nprint(f\"Detected vulnerability: {vulnerability_type}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T03:29:12.689289Z","iopub.execute_input":"2024-09-11T03:29:12.689924Z","iopub.status.idle":"2024-09-11T03:29:13.818974Z","shell.execute_reply.started":"2024-09-11T03:29:12.689893Z","shell.execute_reply":"2024-09-11T03:29:13.817474Z"},"trusted":true},"execution_count":39,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './fine_tuned_roberta'.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the fine-tuned model and tokenizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRobertaForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./fine_tuned_roberta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m RobertaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./fine_tuned_roberta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Detect vulnerabilities in the website code\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3128\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   3127\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 3128\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3141\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3142\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3143\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:466\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n","\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: './fine_tuned_roberta'. Please provide either the path to a local folder or the repo_id of a model on the Hub."],"ename":"OSError","evalue":"Incorrect path_or_model_id: './fine_tuned_roberta'. Please provide either the path to a local folder or the repo_id of a model on the Hub.","output_type":"error"}]}]}